{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dir):\n",
    "    dataset = []\n",
    "    for file in glob.glob(dir + \"/*\"):\n",
    "        with open(file, 'rb') as f:\n",
    "            dataset.append(f.read().decode('utf-8', errors='ignore'))\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dir = 'Data\\spam'\n",
    "easy_ham_dir = 'Data\\easy_ham'\n",
    "hard_ham_dir = 'Data\\hard_ham'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = load_dataset(spam_dir)\n",
    "spam = spam[1:]\n",
    "easy_ham = load_dataset(easy_ham_dir)\n",
    "hard_ham = load_dataset(hard_ham_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header(email):\n",
    "    try:\n",
    "        return email[email.index('\\n\\n')+1:]\n",
    "    except:\n",
    "        print('cannot find header')\n",
    "        print(email)\n",
    "        return email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower_case(email):\n",
    "    return email.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url_regex(email):\n",
    "    return re.findall(r'(https?://[^\\s]+)', email)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_url(email):\n",
    "    urls = find_url_regex(email)\n",
    "    for url in urls:\n",
    "        email = email.replace(url, 'URL')\n",
    "    return email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_numbers_regex(email):\n",
    "    return re.findall(r'\\d+', email)\n",
    "\n",
    "\n",
    "def replace_numbers(email):\n",
    "    numbers = find_numbers_regex(email)\n",
    "    for number in numbers:\n",
    "        email = email.replace(number, 'NUM')\n",
    "    return email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(email):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~\\n\\t'''\n",
    "    for letter in email:\n",
    "        if letter in punctuations:\n",
    "            email = email.replace(letter, '')\n",
    "    return email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(email):\n",
    "    ps = PorterStemmer()\n",
    "    words = word_tokenize(email)\n",
    "    stemmed_words = [ps.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, header=True, footer=True, num=True, punct=True, url=True, stem=True, to_lower=True):\n",
    "        self.header = header\n",
    "        self.footer = footer\n",
    "        self.num = num\n",
    "        self.punct = punct\n",
    "        self.url = url\n",
    "        self.stem = stem\n",
    "        self.to_lower = to_lower\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.header:\n",
    "            X = [remove_header(email) for email in X]\n",
    "        if self.to_lower:\n",
    "            X = [to_lower_case(email) for email in X]\n",
    "        if self.url:\n",
    "            X = [replace_url(email) for email in X]\n",
    "        if self.num:\n",
    "            X = [replace_numbers(email) for email in X]\n",
    "        if self.punct:\n",
    "            X = [remove_punctuation(email) for email in X]\n",
    "        if self.stem:\n",
    "            X = [stem_words(email) for email in X]\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('email_preprocessor', EmailPreprocessor()),\n",
    "                    ('vectorizer', CountVectorizer(decode_error='ignore'))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([spam, easy_ham, hard_ham])\n",
    "y = np.concatenate([np.ones(len(spam)), np.zeros(\n",
    "    len(easy_ham)), np.zeros(len(hard_ham))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newX = pipeline.fit_transform(X)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    newX, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8819969742813918"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC()\n",
    "svm_clf.fit(Xtrain, ytrain)\n",
    "pred = svm_clf.predict(Xtest)\n",
    "accuracy_score(ytest, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9818456883509834"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(max_iter=10000)\n",
    "lr_clf.fit(Xtrain, ytrain)\n",
    "pred = lr_clf.predict(Xtest)\n",
    "accuracy_score(ytest, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9576399394856279"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(Xtrain, ytrain)\n",
    "pred = dt_clf.predict(Xtest)\n",
    "accuracy_score(ytest, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'penalty': ['l1', 'l2'], }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.966 total time=   4.6s\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.962 total time=   3.8s\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.956 total time=   2.9s\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.964 total time=   4.5s\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.968 total time=   4.0s\n",
      "[CV 1/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, penalty=l2;, score=0.977 total time=   6.3s\n",
      "[CV 2/5] END ...................C=1, penalty=l2;, score=0.979 total time=   5.6s\n",
      "[CV 3/5] END ...................C=1, penalty=l2;, score=0.972 total time=   6.3s\n",
      "[CV 4/5] END ...................C=1, penalty=l2;, score=0.975 total time=   6.9s\n",
      "[CV 5/5] END ...................C=1, penalty=l2;, score=0.973 total time=   4.3s\n",
      "[CV 1/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, penalty=l2;, score=0.979 total time=   5.4s\n",
      "[CV 2/5] END ..................C=10, penalty=l2;, score=0.979 total time=   5.7s\n",
      "[CV 3/5] END ..................C=10, penalty=l2;, score=0.972 total time=   4.7s\n",
      "[CV 4/5] END ..................C=10, penalty=l2;, score=0.973 total time=   6.0s\n",
      "[CV 5/5] END ..................C=10, penalty=l2;, score=0.973 total time=   9.3s\n",
      "[CV 1/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=100, penalty=l2;, score=0.979 total time=  10.3s\n",
      "[CV 2/5] END .................C=100, penalty=l2;, score=0.977 total time=   9.5s\n",
      "[CV 3/5] END .................C=100, penalty=l2;, score=0.970 total time=   6.6s\n",
      "[CV 4/5] END .................C=100, penalty=l2;, score=0.972 total time=   6.9s\n",
      "[CV 5/5] END .................C=100, penalty=l2;, score=0.975 total time=   6.3s\n",
      "[CV 1/5] END ..................C=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..................C=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..................C=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..................C=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..................C=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................C=1000, penalty=l2;, score=0.975 total time=   5.3s\n",
      "[CV 2/5] END ................C=1000, penalty=l2;, score=0.977 total time=   6.5s\n",
      "[CV 3/5] END ................C=1000, penalty=l2;, score=0.970 total time=   6.0s\n",
      "[CV 4/5] END ................C=1000, penalty=l2;, score=0.970 total time=   8.4s\n",
      "[CV 5/5] END ................C=1000, penalty=l2;, score=0.975 total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP User\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP User\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP User\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\HP User\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\HP User\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.96325758        nan 0.97537879        nan 0.97537879\n",
      "        nan 0.97462121        nan 0.97348485]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=10000), n_jobs=1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']},\n",
       "             scoring='accuracy', verbose=7)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(max_iter=10000),param_grid,scoring='accuracy',verbose=5,cv=5,n_jobs=1)\n",
    "grid.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9753787878787878"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9818456883509834"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_best = LogisticRegression(**grid.best_params_,max_iter=10000)\n",
    "lr_best.fit(Xtrain,ytrain)\n",
    "pred = lr_best.predict(Xtest)\n",
    "accuracy_score(ytest,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[535,   4],\n",
       "       [  8, 114]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9661016949152542"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(ytest,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344262295081968"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(ytest,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03691a3632807d6770ef8900fc7908ae2b30eee8d6737a4358b5044b138d1db1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
